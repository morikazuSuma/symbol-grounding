#!/usr/bin/env python3
"""
è¨˜å·æŽ¥åœ°å¾…ã¡ Webç‰ˆ æ›´æ–°ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯ä»¥ä¸‹ã‚’è¡Œã„ã¾ã™ï¼š
1. Amazonã»ã—ã„ç‰©ãƒªã‚¹ãƒˆã‹ã‚‰å•†å“æƒ…å ±ã‚’å–å¾—
2. å•†å“ç”»åƒã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
3. data.json ã‚’ç”Ÿæˆ
4. GitHubã«ãƒ—ãƒƒã‚·ãƒ¥
"""

import json
import os
import re
import subprocess
import sys
import time
import urllib.request

# è¨­å®š
WISHLIST_URL = "https://www.amazon.co.jp/hz/wishlist/ls/2UQ7O1570CFAX"
WEB_DIR = os.path.expanduser("~/Desktop/symbol-grounding-web")
IMAGES_DIR = os.path.join(WEB_DIR, "images")

def fetch_wishlist_html(url):
    """ã»ã—ã„ç‰©ãƒªã‚¹ãƒˆã®HTMLã‚’å–å¾—"""
    print(f"ðŸ“¥ ã»ã—ã„ç‰©ãƒªã‚¹ãƒˆã‚’å–å¾—ä¸­: {url}")
    
    headers = {
        'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
        'Accept-Language': 'ja,en-US;q=0.7,en;q=0.3',
    }
    
    req = urllib.request.Request(url, headers=headers)
    
    try:
        with urllib.request.urlopen(req, timeout=30) as response:
            html = response.read().decode('utf-8')
            return html
    except Exception as e:
        print(f"âŒ HTMLã®å–å¾—ã«å¤±æ•—: {e}")
        return None

def parse_wishlist(html):
    """HTMLã‹ã‚‰å•†å“æƒ…å ±ã‚’æŠ½å‡º"""
    print("ðŸ” å•†å“æƒ…å ±ã‚’è§£æžä¸­...")
    
    items = []
    
    item_pattern = re.compile(
        r'id="itemName_([^"]+)"[^>]*title="([^"]*)"[^>]*href="(/dp/([A-Z0-9]+)/[^"]*)"',
        re.DOTALL
    )
    
    img_pattern = re.compile(
        r'src="(https://m\.media-amazon\.com/images/I/[^"]+\._SS135_\.jpg)"'
    )
    
    all_images = img_pattern.findall(html)
    
    for match in item_pattern.finditer(html):
        item_id = match.group(1)
        title = match.group(2)
        href = match.group(3)
        asin = match.group(4)
        
        item_pos = match.start()
        
        img_url = None
        for img in all_images:
            img_pos = html.find(img)
            if img_pos < item_pos and img_pos > item_pos - 2000:
                img_url = img
        
        if not img_url:
            item_index = len(items)
            if item_index < len(all_images):
                img_url = all_images[item_index + 2]
        
        if img_url:
            img_url_hd = img_url.replace('._SS135_.', '._SL500_.')
            
            items.append({
                'id': asin,
                'name': title,
                'url': f'https://www.amazon.co.jp/dp/{asin}',
                'image_url': img_url_hd
            })
            
            print(f"  âœ“ {title[:40]}...")
    
    print(f"ðŸ“š {len(items)} ä»¶ã®å•†å“ã‚’ç™ºè¦‹")
    return items

def download_images(items, output_dir):
    """å•†å“ç”»åƒã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"""
    print(f"\nðŸ“· ç”»åƒã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­...")
    
    os.makedirs(output_dir, exist_ok=True)
    
    downloaded = []
    
    for item in items:
        img_url = item['image_url']
        filename = f"{item['id']}.jpg"
        filepath = os.path.join(output_dir, filename)
        
        if os.path.exists(filepath):
            print(f"  â­ {filename} (æ—¢å­˜)")
            downloaded.append({
                'id': item['id'],
                'image': f"images/{filename}",
                'url': item['url'],
                'name': item['name']
            })
            continue
        
        try:
            headers = {
                'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36',
            }
            req = urllib.request.Request(img_url, headers=headers)
            
            with urllib.request.urlopen(req, timeout=15) as response:
                with open(filepath, 'wb') as f:
                    f.write(response.read())
            
            print(f"  âœ“ {filename}")
            downloaded.append({
                'id': item['id'],
                'image': f"images/{filename}",
                'url': item['url'],
                'name': item['name']
            })
            
            time.sleep(0.5)
            
        except Exception as e:
            print(f"  âŒ {filename}: {e}")
    
    return downloaded

def generate_data_json(items, output_path):
    """data.json ã‚’ç”Ÿæˆ"""
    print(f"\nðŸ“ data.json ã‚’ç”Ÿæˆä¸­...")
    
    data = [
        {
            'id': item['id'],
            'image': item['image'],
            'url': item['url']
        }
        for item in items
    ]
    
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    
    print(f"  âœ“ {len(data)} ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜")

def push_to_github(web_dir):
    """GitHubã«ãƒ—ãƒƒã‚·ãƒ¥"""
    print(f"\nðŸš€ GitHubã«ãƒ—ãƒƒã‚·ãƒ¥ä¸­...")
    
    try:
        os.chdir(web_dir)
        
        # Git add
        subprocess.run(['git', 'add', '.'], check=True)
        
        # Git commit
        result = subprocess.run(
            ['git', 'commit', '-m', f'Update wishlist: {time.strftime("%Y-%m-%d %H:%M")}'],
            capture_output=True,
            text=True
        )
        
        if 'nothing to commit' in result.stdout + result.stderr:
            print("  â„¹ï¸  å¤‰æ›´ãªã—")
            return True
        
        # Git push
        subprocess.run(['git', 'push'], check=True)
        
        print("  âœ“ ãƒ—ãƒƒã‚·ãƒ¥å®Œäº†")
        return True
        
    except Exception as e:
        print(f"  âŒ ãƒ—ãƒƒã‚·ãƒ¥å¤±æ•—: {e}")
        return False

def main():
    print("=" * 50)
    print("ðŸ–¼  è¨˜å·æŽ¥åœ°å¾…ã¡ Webç‰ˆ æ›´æ–°ã‚¹ã‚¯ãƒªãƒ—ãƒˆ")
    print("=" * 50)
    
    # 1. ã»ã—ã„ç‰©ãƒªã‚¹ãƒˆã‚’å–å¾—
    html = fetch_wishlist_html(WISHLIST_URL)
    if not html:
        print("âŒ ã»ã—ã„ç‰©ãƒªã‚¹ãƒˆã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ")
        sys.exit(1)
    
    # 2. å•†å“æƒ…å ±ã‚’è§£æž
    items = parse_wishlist(html)
    if not items:
        print("âŒ å•†å“æƒ…å ±ã®è§£æžã«å¤±æ•—ã—ã¾ã—ãŸ")
        sys.exit(1)
    
    # 3. ç”»åƒã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
    downloaded = download_images(items, IMAGES_DIR)
    
    # 4. data.json ã‚’ç”Ÿæˆ
    data_json_path = os.path.join(WEB_DIR, "data.json")
    generate_data_json(downloaded, data_json_path)
    
    # 5. GitHubã«ãƒ—ãƒƒã‚·ãƒ¥
    if push_to_github(WEB_DIR):
        print("\n" + "=" * 50)
        print("âœ… æ›´æ–°å®Œäº†ï¼")
        print("   https://morikazusuma.github.io/symbol-grounding/")
        print("=" * 50)
    else:
        print("\nâš ï¸  ãƒ—ãƒƒã‚·ãƒ¥ã«å¤±æ•—ã—ã¾ã—ãŸãŒã€ãƒ­ãƒ¼ã‚«ãƒ«ã¯æ›´æ–°ã•ã‚Œã¾ã—ãŸ")
        print("   æ‰‹å‹•ã§git pushã—ã¦ãã ã•ã„")

if __name__ == "__main__":
    main()
